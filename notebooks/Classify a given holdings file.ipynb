{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Fossil Classification for a given Holding File\n",
    "## Prepare environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fossil_classification import *\n",
    "from enrich_holdings import *\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.options.display.float_format = \"{:,.2f}\".format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify quarterly holdings file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Preparing holding file\n",
      "\n",
      "** Holdings file for classification **\n",
      "data/downloaded reports/company reports/2022Q3/holdings_for_cls.csv\n",
      "columns: Index(['שם המנפיק/שם נייר ערך', 'מספר ני\"ע', 'מספר מנפיק', 'שווי',\n",
      "       'שעור מנכסי אפיק ההשקעה', 'שעור מסך נכסי השקעה', 'holding_type',\n",
      "       'זירת מסחר', 'תאריך רכישה', 'ערך נקוב', 'שער', 'שעור מערך נקוב מונפק',\n",
      "       'ענף מסחר', 'SystemName', 'ParentCorpName', 'ReportPeriodDesc'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/urimarom/PycharmProjects/fossil_classification/fossil_classification.py:79: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  isin_cnt = sum(df[col].astype(str).str.strip().str.contains(isin_pattern, na=False))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Holding file ISIN col is: מספר ני\"ע\n",
      "number of ISINs: 7485 out of 27691 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/urimarom/PycharmProjects/fossil_classification/fossil_classification.py:101: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  pattern_cnt = sum(df[col].astype(str).str.strip().str.contains(pattern, na=False))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Holding file Israel Corp col is: מספר מנפיק\n",
      "number of Israel Corp Numbers: 19084 out of 27691 rows\n",
      "\n",
      "2. Preparing mapping files\n",
      "\n",
      "3. Enriching holding file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/urimarom/PycharmProjects/fossil_classification/enrich_holdings.py:128: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  cnt = sum(df[col].astype(str).str.strip().str.contains(pattern, na=False))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Holding file ISIN col is: מספר ני\"ע\n",
      "number of ISINs: 7513 out of 27691 rows\n",
      "\n",
      "Holding file מספר תאגיד col is: מספר מנפיק\n",
      "number of מספר תאגידs: 19084 out of 27691 rows\n",
      "\n",
      "no LEIs in holdings file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/urimarom/PycharmProjects/fossil_classification/enrich_holdings.py:165: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df[id_cols[id_type]] = df[id_cols[id_type]].str.replace(id_col_patterns(id_type), \"\")\n",
      "/Users/urimarom/PycharmProjects/fossil_classification/enrich_holdings.py:167: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  matching_type = df[id_type].str.contains(id_col_patterns(id_type), na=False)\n",
      "/Users/urimarom/PycharmProjects/fossil_classification/enrich_holdings.py:165: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df[id_cols[id_type]] = df[id_cols[id_type]].str.replace(id_col_patterns(id_type), \"\")\n",
      "/Users/urimarom/PycharmProjects/fossil_classification/enrich_holdings.py:167: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  matching_type = df[id_type].str.contains(id_col_patterns(id_type), na=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "מספר ני\"עs with matching ISIN: 22771 out of total relevant rows: 20178\n",
      "מספר תאגידs with matching מספר מנפיק: 20181 out of total relevant rows: 19084\n",
      "מספר ני\"עs with matching מספר מנפיק: 20206 out of total relevant rows: 20178\n",
      "ISINs with matching מספר מנפיק: 20258 out of total relevant rows: 22771\n",
      "ISINs with matching LEI: 4333 out of total relevant rows: 22771\n",
      "\n",
      "4. Preparing previously classified file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/urimarom/PycharmProjects/fossil_classification/enrich_holdings.py:128: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  cnt = sum(df[col].astype(str).str.strip().str.contains(pattern, na=False))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Holding file ISIN col is: ISIN\n",
      "number of ISINs: 232809 out of 277778 rows\n",
      "\n",
      "Holding file מספר תאגיד col is: מספר תאגיד\n",
      "number of מספר תאגידs: 182214 out of 277778 rows\n",
      "\n",
      "Holding file LEI col is: LEI\n",
      "number of LEIs: 48658 out of 277778 rows\n",
      "מספר ני\"עs with matching ISIN: 234684 out of total relevant rows: 195173\n",
      "מספר תאגידs with matching מספר מנפיק: 196266 out of total relevant rows: 182214\n",
      "מספר ני\"עs with matching מספר מנפיק: 196287 out of total relevant rows: 195173\n",
      "ISINs with matching מספר מנפיק: 196324 out of total relevant rows: 234684\n",
      "ISINs with matching LEI: 48770 out of total relevant rows: 234684\n",
      "\n",
      "5. Matching holdings with previously classified\n",
      "\n",
      "1. matching to previously classified by Israeli security number\n",
      "\n",
      "previous is_fossil coverage\n",
      "Israeli security numbers previously classified: 19739 out of total holdings: 27691\n",
      "\n",
      "2. matching to previously classified by ISIN\n",
      "\n",
      "previous is_fossil coverage\n",
      "ISINs previously classified: 22414 out of total holdings: 27691\n",
      "\n",
      "3. matching to previously classified by issuer number\n",
      "issuers previously classified: 20206 out of total holdings: 27691\n",
      "\n",
      "4. matching to previously classified by LEI\n",
      "LEIs previously classified: 4307 out of total holdings: 27691\n",
      "\n",
      "5. matching to previously classified by מספר תאגיד\n",
      "Israeli Corp Nums previously classified: 19026 out of total holdings: 27691\n",
      "\n",
      "** Fetching tlv companies fossil classification **\n",
      "\n",
      "is_fossil in TLV companies classification\n",
      "0    543\n",
      "1     48\n",
      "Name: רשימה שחורה, dtype: int64\n",
      "\n",
      "*** TLV companies with missing fossil classification ***\n",
      "Empty DataFrame\n",
      "Columns: [מספר מנפיק, מספר תאגיד, שם, שם מלא, ענף בבורסה, מדד תל אביב 125, רשימה שחורה, קריטריון פסילה, מדוע נפסל + מקור, כתובת, טלפון, אתר הבית, דואר אלקטרוני]\n",
      "Index: []\n",
      "\n",
      "TLV list is_fossil coverage: by issuer\n",
      "classified: 0 out of total holdings: 27691\n",
      "Number of rows: 591 , Number of unique IL corps: 532\n",
      "\n",
      "TLV list is_fossil coverage: by IL corp num\n",
      "classified: 0 out of total holdings: 27691\n",
      "\n",
      "6. Preparing Fossil Free Funds company list\n",
      "Using data_sources/Invest+Your+Values+company+screens.xlsx\n",
      "\n",
      "is_fossil in Fossil Free Funds list\n",
      "0    3857\n",
      "1    2465\n",
      "Name: fff_fossil_any, dtype: int64\n",
      "\n",
      "Fossil tags breakdown\n",
      "Oil / Gas     0          1    \n",
      "Utilities     0    1     0   1\n",
      "Coal                          \n",
      "0          3857  343  1634  30\n",
      "1           267  168     9  14\n",
      "\n",
      "7. Matchinging holdings with Fossil Free Funds company list\n",
      "\n",
      "** fuzzy matching company names ** (this could take a few minutes)\n",
      "Matching by Company Name coverage:\n",
      "classified: 1739 out of total holdings: 27691\n",
      "\n",
      "8. Calculating is_fossil\n",
      "\n",
      "***** Final Results before propagation *****\n",
      "is_fossil coverage:\n",
      "0.00    24249\n",
      "1.00     3243\n",
      "NaN       199\n",
      "Name: is_fossil, dtype: int64\n",
      "\n",
      "9. Propagating is_fossil across il_sec_num, ISIN and LEI\n",
      "\n",
      "Propagating by מספר ני\"ע\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/urimarom/PycharmProjects/fossil_classification/fossil_classification.py:723: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prop_col_not_null['is_fossil'] = grouped_by_prop_col['is_fossil'].transform(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "is_fossil coverage before propagation by מספר ני\"ע:\n",
      "0.00    24249\n",
      "1.00     3243\n",
      "NaN       199\n",
      "Name: is_fossil, dtype: int64\n",
      "\n",
      "is_fossil coverage after propagation by מספר ני\"ע:\n",
      "0.00    24250\n",
      "1.00     3243\n",
      "NaN       198\n",
      "Name: is_fossil, dtype: int64\n",
      "\n",
      "Propagating by ISIN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/urimarom/PycharmProjects/fossil_classification/fossil_classification.py:723: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prop_col_not_null['is_fossil'] = grouped_by_prop_col['is_fossil'].transform(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "is_fossil coverage before propagation by ISIN:\n",
      "0.00    24250\n",
      "1.00     3243\n",
      "NaN       198\n",
      "Name: is_fossil, dtype: int64\n",
      "\n",
      "is_fossil coverage after propagation by ISIN:\n",
      "0.00    24251\n",
      "1.00     3243\n",
      "NaN       197\n",
      "Name: is_fossil, dtype: int64\n",
      "\n",
      "Propagating by LEI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/urimarom/PycharmProjects/fossil_classification/fossil_classification.py:723: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prop_col_not_null['is_fossil'] = grouped_by_prop_col['is_fossil'].transform(\n",
      "/Users/urimarom/PycharmProjects/fossil_classification/fossil_classification.py:669: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df[\"is_fossil_conflict\"] = df[is_fossil_cols].mean(axis=1).between(0, 1, inclusive=False)\n",
      "/Users/urimarom/PycharmProjects/fossil_classification/fossil_classification.py:669: FutureWarning: Boolean inputs to the `inclusive` argument are deprecated in favour of `both` or `neither`.\n",
      "  df[\"is_fossil_conflict\"] = df[is_fossil_cols].mean(axis=1).between(0, 1, inclusive=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "is_fossil coverage before propagation by LEI:\n",
      "0.00    24251\n",
      "1.00     3243\n",
      "NaN       197\n",
      "Name: is_fossil, dtype: int64\n",
      "\n",
      "is_fossil coverage after propagation by LEI:\n",
      "0.00    24251\n",
      "1.00     3243\n",
      "NaN       197\n",
      "Name: is_fossil, dtype: int64\n",
      "\n",
      "Writing results to data/downloaded reports/company reports/2022Q3/holdings_for_cls with fossil classification.csv\n"
     ]
    }
   ],
   "source": [
    "holdings_path = \"data/downloaded reports/company reports/2022Q3/holdings_for_cls.csv\"\n",
    "classify_holdings(holdings_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Review\n",
    "In a google spreadsheet or excel.\n",
    "Download the fully classifed file into a csv, then use it in holding_cls_path to update prev_class (see below).\n",
    "\n",
    "## Tips\n",
    "1. Look at the output of the script, review conflicting classification (by ISIN, LEI, Israeli security number)\n",
    "2. Look at holdings that get is_fossil_conflict=True\n",
    "3. Sort by security name, Israeli security number or ISIN for faster manual classification\n",
    "4. Carefully review holdings that have only is_fossil by FFF name match, as there are false matches.\n",
    "<br>Review both holdings for which all the other is_fossil_x flags are null, and such that have is_fossil by FFF = 1and other is_fossil_x = 0\n",
    "5. Review holdings from suspicious industries: energy, oil and gas, utilities, materials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add classification results to prev_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding classifications to prev_class, saving the previous version as data_sources/prev_class backup/prev_class 2022-12-12 21-06-15.csv\n"
     ]
    }
   ],
   "source": [
    "holdings_cls_path = \"data/downloaded reports/company reports/2022Q3/holdings_for_cls with fossil classification - reviewed.csv\"\n",
    "prev_class_path = \"data_sources/prev_class.csv\"\n",
    "update_prev_class(holdings_cls_path, prev_class_path)\n",
    "# prev_class_fixed = add_all_id_types_to_holdings(prev_class, tlv_s2i, isin2lei)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify fund holdings\n",
    "## Israeli funds\n",
    "Data is scraped from https://mayaapi.tase.co.il/api/fund/details?fundId=\n",
    "<br>Page address: https://maya.tase.co.il/fund/5132287?view=assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_directory = \"data/holdings_for_classification/5132287/\"\n",
    "response_path = response_directory + \"response.json\"\n",
    "fund = pd.read_json(response_path, orient=\"index\")\n",
    "assets = pd.DataFrame(fund.loc[\"AssetCompostion\"][0]['Assets'])\n",
    "# holdings[\"AssetCompostion\"].head()\n",
    "cols_rename = {\n",
    "    'AssetName': 'שם המנפיק/שם נייר ערך',\n",
    "    'IdentityCd': 'מספר ני\"ע',\n",
    "    'Id': 'fund_id'\n",
    "}\n",
    "assets = assets.rename(cols_rename, axis=1)\n",
    "assets[\"מספר מנפיק\"] = '00'\n",
    "assets[\"מספר תאגיד\"] = '00'\n",
    "assets.to_csv(response_directory+\"assets.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Preparing holding file\n",
      "\n",
      "** Holdings file for classification **\n",
      "data/holdings_for_classification/5132287/assets.csv\n",
      "columns: Index(['מספר ני\"ע', 'שם המנפיק/שם נייר ערך', 'AssetTypeName', 'FundPercentage',\n",
      "       'NisValue', 'Price', 'Quantity', 'BondRank', 'Graph', 'fund_id',\n",
      "       'ManagerId', 'מספר מנפיק', 'מספר תאגיד'],\n",
      "      dtype='object')\n",
      "\n",
      "Holding file ISIN col is: מספר ני\"ע\n",
      "number of ISINs: 35 out of 38 rows\n",
      "\n",
      "ERROR: no Israel Corp Numbers in holdings file, reverting to default: מספר מנפיק\n",
      "\n",
      "2. Preparing mapping files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/urimarom/PycharmProjects/fossil_classification/fossil_classification.py:79: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  isin_cnt = sum(df[col].astype(str).str.strip().str.contains(isin_pattern, na=False))\n",
      "/Users/urimarom/PycharmProjects/fossil_classification/fossil_classification.py:101: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  pattern_cnt = sum(df[col].astype(str).str.strip().str.contains(pattern, na=False))\n"
     ]
    },
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mclassify_holdings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_directory\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43massets.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PycharmProjects/fossil_classification/fossil_classification.py:755\u001b[0m, in \u001b[0;36mclassify_holdings\u001b[0;34m(holdings_path, holdings_ticker_col, holdings_company_col, sheet_num)\u001b[0m\n\u001b[1;32m    753\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m2. Preparing mapping files\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    754\u001b[0m tlv_s2i \u001b[38;5;241m=\u001b[39m prepare_tlv_sec_num_to_issuer(fetch_latest_tlv_sec_num_to_issuer())\n\u001b[0;32m--> 755\u001b[0m isin2lei \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_latest_isin2lei\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    756\u001b[0m \u001b[38;5;66;03m# 3. enrich holdings file\u001b[39;00m\n\u001b[1;32m    757\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m3. Enriching holding file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/PycharmProjects/fossil_classification/enrich_holdings.py:246\u001b[0m, in \u001b[0;36mfetch_latest_isin2lei\u001b[0;34m(isin2lei_path)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch_latest_isin2lei\u001b[39m(isin2lei_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_sources/ISIN_LEI.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;66;03m# TODO: Fetch automatically from website\u001b[39;00m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;66;03m# https://www.gleif.org/en/lei-data/lei-mapping/download-isin-to-lei-relationship-files\u001b[39;00m\n\u001b[0;32m--> 246\u001b[0m     isin2lei \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43misin2lei_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m isin2lei\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:581\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1254\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1252\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1253\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1254\u001b[0m     index, columns, col_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1255\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1256\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py:225\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 225\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    227\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/parsers.pyx:805\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/parsers.pyx:861\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/parsers.pyx:847\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/parsers.pyx:1960\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."
     ]
    }
   ],
   "source": [
    "classify_holdings(response_directory+\"assets.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## holdings CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdings_csv_dir = \"/Users/urimarom/PycharmProjects/fossil_classification/data/holdings_for_classification/IE000PSF3A70/\"\n",
    "holdings_filename = 'fund_weights.csv'\n",
    "holdings_csv_path = holdings_csv_dir + holdings_filename\n",
    "holdings = pd.read_csv(holdings_csv_path)\n",
    "cols_rename = {\n",
    "    'Name': 'שם המנפיק/שם נייר ערך',\n",
    "    'ISIN': 'מספר ני\"ע',\n",
    "    'Type of Security': 'holding_type'\n",
    "}\n",
    "holdings = holdings.rename(cols_rename, axis=1)\n",
    "# fix missing columns\n",
    "holdings[\"מספר מנפיק\"] = '00'\n",
    "holdings[\"מספר תאגיד\"] = '00'\n",
    "holdings[\"is_fossil_prev_il_sec_num\"] = np.nan\n",
    "holdings.to_csv(holdings_csv_dir+\"fund_weights_fixed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Preparing holding file\n",
      "\n",
      "** Holdings file for classification **\n",
      "/Users/urimarom/PycharmProjects/fossil_classification/data/holdings_for_classification/IE000PSF3A70/fund_weights_fixed.csv\n",
      "columns: Index(['שם המנפיק/שם נייר ערך', 'מספר ני\"ע', 'Country', 'Currency', 'Exchange',\n",
      "       'holding_type', 'Rating', 'Primary Listing', 'Industry Classification',\n",
      "       'Weighting', 'Unnamed: 10', 'מספר מנפיק', 'מספר תאגיד',\n",
      "       'is_fossil_prev_il_sec_num'],\n",
      "      dtype='object')\n",
      "\n",
      "Holding file ISIN col is: מספר ני\"ע\n",
      "number of ISINs: 281 out of 300 rows\n",
      "\n",
      "ERROR: no Israel Corp Numbers in holdings file, reverting to default: מספר מנפיק\n",
      "\n",
      "2. Preparing mapping files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/urimarom/PycharmProjects/fossil_classification/fossil_classification.py:79: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  isin_cnt = sum(df[col].astype(str).str.strip().str.contains(isin_pattern, na=False))\n",
      "/Users/urimarom/PycharmProjects/fossil_classification/fossil_classification.py:101: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  pattern_cnt = sum(df[col].astype(str).str.strip().str.contains(pattern, na=False))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. Enriching holding file\n",
      "\n",
      "Holding file ISIN col is: מספר ני\"ע\n",
      "number of ISINs: 281 out of 300 rows\n",
      "\n",
      "no מספר תאגידs in holdings file\n",
      "\n",
      "no LEIs in holdings file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/urimarom/PycharmProjects/fossil_classification/enrich_holdings.py:128: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  cnt = sum(df[col].astype(str).str.strip().str.contains(pattern, na=False))\n",
      "/Users/urimarom/PycharmProjects/fossil_classification/enrich_holdings.py:165: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df[id_cols[id_type]] = df[id_cols[id_type]].str.replace(id_col_patterns(id_type), \"\")\n",
      "/Users/urimarom/PycharmProjects/fossil_classification/enrich_holdings.py:167: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  matching_type = df[id_type].str.contains(id_col_patterns(id_type), na=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "מספר ני\"עs with matching ISIN: 281 out of total relevant rows: 19\n",
      "מספר תאגידs with matching מספר מנפיק: 0 out of total relevant rows: 300\n",
      "מספר ני\"עs with matching מספר מנפיק: 0 out of total relevant rows: 19\n",
      "ISINs with matching מספר מנפיק: 1 out of total relevant rows: 281\n",
      "ISINs with matching LEI: 154 out of total relevant rows: 281\n",
      "\n",
      "4. Preparing previously classified file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/urimarom/PycharmProjects/fossil_classification/enrich_holdings.py:128: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  cnt = sum(df[col].astype(str).str.strip().str.contains(pattern, na=False))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Holding file ISIN col is: ISIN\n",
      "number of ISINs: 285920 out of 343191 rows\n",
      "\n",
      "Holding file מספר תאגיד col is: מספר תאגיד\n",
      "number of מספר תאגידs: 227084 out of 343191 rows\n",
      "\n",
      "Holding file LEI col is: LEI\n",
      "number of LEIs: 58732 out of 343191 rows\n",
      "מספר ני\"עs with matching ISIN: 323647 out of total relevant rows: 242772\n",
      "מספר תאגידs with matching מספר מנפיק: 247183 out of total relevant rows: 227084\n",
      "מספר ני\"עs with matching מספר מנפיק: 247638 out of total relevant rows: 242772\n",
      "ISINs with matching מספר מנפיק: 249173 out of total relevant rows: 323647\n",
      "ISINs with matching LEI: 61674 out of total relevant rows: 323647\n",
      "\n",
      "5. Matching holdings with previously classified\n",
      "\n",
      "1. matching to previously classified by Israeli security number\n",
      "\n",
      "previous is_fossil coverage\n",
      "Israeli security numbers previously classified: is_fossil_prev_il_sec_num    0\n",
      "is_fossil_prev_il_sec_num    0\n",
      "dtype: int64 out of total holdings: 300\n",
      "\n",
      "2. matching to previously classified by ISIN\n",
      "\n",
      "previous is_fossil coverage\n",
      "ISINs previously classified: 128 out of total holdings: 300\n",
      "\n",
      "3. matching to previously classified by issuer number\n",
      "issuers previously classified: 1 out of total holdings: 300\n",
      "\n",
      "4. matching to previously classified by LEI\n",
      "LEIs previously classified: 92 out of total holdings: 300\n",
      "\n",
      "5. matching to previously classified by מספר תאגיד\n",
      "Israeli Corp Nums previously classified: 0 out of total holdings: 300\n",
      "\n",
      "** Fetching tlv companies fossil classification **\n",
      "\n",
      "is_fossil in TLV companies classification\n",
      "0    543\n",
      "1     48\n",
      "Name: רשימה שחורה, dtype: int64\n",
      "\n",
      "*** TLV companies with missing fossil classification ***\n",
      "Empty DataFrame\n",
      "Columns: [מספר מנפיק, מספר תאגיד, שם, שם מלא, ענף בבורסה, מדד תל אביב 125, רשימה שחורה, קריטריון פסילה, מדוע נפסל + מקור, כתובת, טלפון, אתר הבית, דואר אלקטרוני]\n",
      "Index: []\n",
      "\n",
      "TLV list is_fossil coverage: by issuer\n",
      "classified: 1 out of total holdings: 300\n",
      "Number of rows: 531 , Number of unique IL corps: 531\n",
      "\n",
      "TLV list is_fossil coverage: by IL corp num\n",
      "classified: 0 out of total holdings: 300\n",
      "\n",
      "6. Preparing Fossil Free Funds company list\n",
      "Using data_sources/Invest+Your+Values+company+screens.xlsx\n",
      "\n",
      "is_fossil in Fossil Free Funds list\n",
      "0    3857\n",
      "1    2465\n",
      "Name: fff_fossil_any, dtype: int64\n",
      "\n",
      "Fossil tags breakdown\n",
      "Oil / Gas     0          1    \n",
      "Utilities     0    1     0   1\n",
      "Coal                          \n",
      "0          3857  343  1634  30\n",
      "1           267  168     9  14\n",
      "\n",
      "7. Matchinging holdings with Fossil Free Funds company list\n",
      "\n",
      "** fuzzy matching company names ** (this could take a few minutes)\n",
      "Matching by Company Name coverage:\n",
      "classified: 100 out of total holdings: 300\n",
      "\n",
      "8. Calculating is_fossil\n",
      "\n",
      "***** Final Results before propagation *****\n",
      "is_fossil coverage:\n",
      "0.00    172\n",
      "NaN     124\n",
      "1.00      4\n",
      "Name: is_fossil, dtype: int64\n",
      "\n",
      "9. Propagating is_fossil across il_sec_num, ISIN and LEI\n",
      "\n",
      "Propagating by מספר ני\"ע\n",
      "\n",
      "is_fossil coverage before propagation by מספר ני\"ע:\n",
      "0.00    172\n",
      "NaN     124\n",
      "1.00      4\n",
      "Name: is_fossil, dtype: int64\n",
      "\n",
      "is_fossil coverage after propagation by מספר ני\"ע:\n",
      "0.00    172\n",
      "NaN     124\n",
      "1.00      4\n",
      "Name: is_fossil, dtype: int64\n",
      "\n",
      "Propagating by ISIN\n",
      "\n",
      "is_fossil coverage before propagation by ISIN:\n",
      "0.00    172\n",
      "NaN     124\n",
      "1.00      4\n",
      "Name: is_fossil, dtype: int64\n",
      "\n",
      "is_fossil coverage after propagation by ISIN:\n",
      "0.00    172\n",
      "NaN     124\n",
      "1.00      4\n",
      "Name: is_fossil, dtype: int64\n",
      "\n",
      "Propagating by LEI\n",
      "\n",
      "is_fossil coverage before propagation by LEI:\n",
      "0.00    172\n",
      "NaN     124\n",
      "1.00      4\n",
      "Name: is_fossil, dtype: int64\n",
      "\n",
      "is_fossil coverage after propagation by LEI:\n",
      "0.00    172\n",
      "NaN     124\n",
      "1.00      4\n",
      "Name: is_fossil, dtype: int64\n",
      "\n",
      "Writing results to /Users/urimarom/PycharmProjects/fossil_classification/data/holdings_for_classification/IE000PSF3A70/fund_weights_fixed with fossil classification.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/urimarom/PycharmProjects/fossil_classification/fossil_classification.py:723: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prop_col_not_null['is_fossil'] = grouped_by_prop_col['is_fossil'].transform(\n",
      "/Users/urimarom/PycharmProjects/fossil_classification/fossil_classification.py:723: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prop_col_not_null['is_fossil'] = grouped_by_prop_col['is_fossil'].transform(\n",
      "/Users/urimarom/PycharmProjects/fossil_classification/fossil_classification.py:723: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prop_col_not_null['is_fossil'] = grouped_by_prop_col['is_fossil'].transform(\n",
      "/Users/urimarom/PycharmProjects/fossil_classification/fossil_classification.py:669: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df[\"is_fossil_conflict\"] = df[is_fossil_cols].mean(axis=1).between(0, 1, inclusive=False)\n",
      "/Users/urimarom/PycharmProjects/fossil_classification/fossil_classification.py:669: FutureWarning: Boolean inputs to the `inclusive` argument are deprecated in favour of `both` or `neither`.\n",
      "  df[\"is_fossil_conflict\"] = df[is_fossil_cols].mean(axis=1).between(0, 1, inclusive=False)\n"
     ]
    }
   ],
   "source": [
    "classify_holdings(holdings_csv_dir+\"fund_weights_fixed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
