{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Fossil Classification for a given Holding File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fossil_classification import *\n",
    "from enrich_holdings import *\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.options.display.float_format = \"{:,.2f}\".format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdings_path = \"data/holdings_for_classification/missing_cls.csv\"\n",
    "holdings = pd.read_csv(holdings_path, dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/urimarom/anaconda3/lib/python3.6/site-packages/pandas/core/strings.py:2001: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "holdings_fixed = fix_id_cols(holdings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6347305389221557"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holdings_fixed['מספר ני\"ע'].notnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next steps:\n",
    "1. enrich fixed holdings:\n",
    "   * add LEI by ISIN\n",
    "   * add מספר מנפיק by מספר תאגיד\n",
    "   * add מספר מנפיק by מספר ני\"ע   \n",
    "   * add issuer number by ISIN for ILXXX ISINs (or try for all and see?)\n",
    "2. check after enriching - how many missing issuer_num for Israeli holdings?\n",
    "3. update fossil_classification, use new enriching and merge by the new clean columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "** Holdings file for classification **\n",
      "missing_cls.csv\n",
      "columns: Index(['שם המנפיק/שם נייר ערך', 'מספר ני\"ע', 'מספר מנפיק'], dtype='object')\n",
      "\n",
      "Holding file ISIN col is: מספר ני\"ע\n",
      "number of ISINs: 98 out of 334 rows\n",
      "\n",
      "Holding file Israel Corp col is: מספר מנפיק\n",
      "number of Israel Corp Numbers: 157 out of 334 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/urimarom/anaconda3/lib/python3.6/site-packages/pandas/core/strings.py:2001: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holdings with matching issuer number after joining by מספר ני\"ע: 247 out of total holdings 334\n",
      "Holdings with matching issuer number after joining by מספר מנפיק: 247 out of total holdings 334\n",
      "ISINs with matching LEI: 87 out of total rows: 334\n",
      "\n",
      "** Previously classified ISINs and corps **\n",
      "is_fossil in previously classified\n",
      "0.00    6930\n",
      "1.00     564\n",
      "Name: is_fossil, dtype: int64\n",
      "\n",
      "*** Issuers with both is_fossil=1 and is_fossil=0 ***\n",
      "                                        Name  security_num issuer_or_corp_num  \\\n",
      "8641                    ENOIGA 5.875 30/3/31  IL0011736811                995   \n",
      "8690                    ENOIGA 5.375 30/3/28  IL0011736738                995   \n",
      "8702                     ISRELE 4.25 14/8/28  IL0060002446                995   \n",
      "15926                         DOX 2.538 6/30  US02342TAE91                995   \n",
      "16505                           NVMI 0 10/25  US66980MAA45                995   \n",
      "17225                        HKINTL 3.132 27  XS1555404786                995   \n",
      "17584                          ORSTED 2.5 21  XS2293681685                995   \n",
      "125               CANADIAN NATURAL RESOURCES  CA1363851017              97719   \n",
      "4618                         R NATL CANADIAN  CA1363751027              97719   \n",
      "5218   ELLO US Ellomany Cap Ltd- אלומי קפיטל  IL0010826357          520039868   \n",
      "35449                           אלומיי אגח ב       1140326          520039868   \n",
      "\n",
      "       is_fossil classification_date  \n",
      "8641        1.00          2021-10-01  \n",
      "8690        1.00          2021-10-01  \n",
      "8702        1.00          2021-10-01  \n",
      "15926       0.00          2021-10-01  \n",
      "16505       0.00          2021-10-01  \n",
      "17225       0.00          2021-10-01  \n",
      "17584       0.00          2021-10-01  \n",
      "125         1.00          2021-10-01  \n",
      "4618        0.00          2021-10-01  \n",
      "5218        0.00          2021-10-01  \n",
      "35449       1.00                 NaN  \n",
      "Holdings with matching issuer number after joining by security_num: 1120 out of total holdings 7494\n",
      "ISINs with matching LEI: 3754 out of total rows: 7494\n",
      "\n",
      "Writing results to prev with added issuer and LEI.csv\n",
      "\n",
      "1. matching to previously classified by ISIN / security number\n",
      "\n",
      "previous is_fossil coverage\n",
      "ISINs previously classified: 23 out of total holdings: 334\n",
      "\n",
      "2. matching to previously classified by issuer number\n",
      "issuers previously classified: 133 out of total holdings: 334\n",
      "\n",
      "3. matching to previously classified by LEI\n",
      "LEIs previously classified: 71 out of total holdings: 334\n",
      "\n",
      "** Fetching tlv companies fossil classification **\n",
      "\n",
      "is_fossil in TLV companies classification\n",
      "0    544\n",
      "1     47\n",
      "Name: רשימה שחורה, dtype: int64\n",
      "\n",
      "*** TLV companies with missing fossil classification ***\n",
      "Empty DataFrame\n",
      "Columns: [מספר מנפיק, מספר תאגיד, שם, שם מלא, ענף בבורסה, מדד תל אביב 125, רשימה שחורה, קריטריון פסילה, מדוע נפסל + מקור, כתובת, טלפון, אתר הבית, דואר אלקטרוני]\n",
      "Index: []\n",
      "\n",
      "TLV list is_fossil coverage\n",
      "classified: 134 out of total holdings: 334\n",
      "Using ../../data_sources/Invest+Your+Values+company+screens.xlsx\n",
      "\n",
      "is_fossil in Fossil Free Funds list\n",
      "0    3851\n",
      "1    2526\n",
      "Name: fff_fossil_any, dtype: int64\n",
      "\n",
      "Fossil tags breakdown\n",
      "Oil / Gas     0          1   \n",
      "Utilities     0    1     0  1\n",
      "Coal                         \n",
      "0          3851  369  1687  2\n",
      "1           276  182     7  3\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Instrument Name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2898\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Instrument Name'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-0c0a3759c5cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m classify_holdings(\n\u001b[1;32m     10\u001b[0m      \u001b[0mholdings_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mholdings_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m      \u001b[0mholdings_ticker_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mholdings_ticker_col\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m      )\n",
      "\u001b[0;32m~/PycharmProjects/fossil_classification/fossil_classification.py\u001b[0m in \u001b[0;36mclassify_holdings\u001b[0;34m(tlv_path, prev_class_path, isin2lei_path, holdings_path, holdings_corp_or_issuer_col, holdings_ticker_col, holdings_company_col, sheet_num)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0mcommon_words_in_company\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m         \u001b[0mholdings_company_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mholdings_company_col\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m         \u001b[0mfff_company_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Company\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m     )\n\u001b[1;32m    779\u001b[0m     \u001b[0;31m# TODO: inner matching - consolidate to issuer based on ISIN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/fossil_classification/fossil_classification.py\u001b[0m in \u001b[0;36mmatch_holdings_with_fff_by_company_name\u001b[0;34m(holdings, fff, common_words_in_company, holdings_company_col, fff_company_col, min_match_threshold, is_fossil_match_threshold)\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;31m# prepare company names for fuzzy matching\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;31m# remove common words (LTD, Corp etc.)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m     \u001b[0mholdings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"company_clean\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mholdings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mholdings_company_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mclean_company\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mholdings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"company_clean\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_common_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mholdings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"company_clean\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommon_words_in_company\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m     \u001b[0;31m# TODO: maybe use ASA, PLC, INC etc. as separator? remove everything after separator if got >= n (3?) words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2898\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2900\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2902\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Instrument Name'"
     ]
    }
   ],
   "source": [
    "holdings_path = \"missing_cls.csv\"\n",
    "# tlv_path = \"../../data_sources/TASE companies - fossil classification.xlsx\"\n",
    "# prev_class_path = \"../../data_sources/prev_class.csv\"\n",
    "# isin2lei_path = \"../../data_sources/ISIN_LEI.csv\"\n",
    "# holdings_corp_or_issuer_col = \"מספר מנפיק\"\n",
    "holdings_ticker_col = None\n",
    "# holdings_company_col = \"שם המנפיק/שם נייר ערך\"\n",
    "\n",
    "classify_holdings(\n",
    "     holdings_path=holdings_path,\n",
    "     holdings_ticker_col=holdings_ticker_col,\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_fossil_classification = pd.read_csv(prev_class_path)\n",
    "prev_fossil_classification.sort_values([\"classification_date\", \"issuer_or_corp_num\"], ascending=False, inplace=True)\n",
    "prev_fossil_classification_deduped = prev_fossil_classification.drop_duplicates([\"security_num\", \"issuer_or_corp_num\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_fossil_classification_deduped[prev_fossil_classification_deduped[\"security_num\"].str.startswith(\"1\")].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
